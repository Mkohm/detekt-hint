\documentclass{report}
\usepackage[utf8]{inputenc}
\usepackage[acronym]{glossaries}
\usepackage{biblatex}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{graphicx}
\usepackage{pgfplots}
\usepackage{fancyvrb}

\addbibresource{bibliography.bib}


\title{Detekt-hint -- Detection of design principle violations}
\author{Marius Kohmann}
\date{June 2020}


\newacronym{ast}{AST}{Abstract Syntax Tree}
\newacronym{solid}{SOLID}{\textbf{S}ingle responsibility, \textbf{O}pen–closed, \textbf{L}iskov substitution, \textbf{I}nterface segregation, \textbf{D}ependency inversion}
\newacronym{dry}{DRY}{Don't Repeat Yourself}
\newacronym{srp}{SRP}{Single Responsibility Principle}
\newacronym{ocp}{OCP}{Open-Closed Principle}
\newacronym{lsp}{LSP}{Liskov Substitution Principle}
\newacronym{isp}{ISP}{Interface Segregation Principle}
\newacronym{dip}{DIP}{Dependency Inversion Principle}
\newacronym{lcom}{LCOM}{Lack of Cohesion Of Methods}
\newacronym{loc}{LOC}{Lines Of Code}
\newacronym{mvvm}{MVVM}{Model-View-ViewModel}
\newacronym{pr}{PR}{Pull Request}
\newacronym{ntnu}{NTNU}{Norwegian University of Science and Technology}
\newacronym{mimc}{MIMC}{More Is More Complex}
\newacronym{kiss}{KISS}{Keep It Simple Stupid}
\newacronym{psi}{PSI}{Program Structure Interface}
\newacronym{dsm}{DSM}{Dependency Structure Matrix}
\newacronym{lod}{LoD}{Law of Demeter}
\newacronym{ide}{IDE}{Integrated Development Environment}
\newacronym{cli}{CLI}{Command Line Interface}
\newacronym{qa}{QA}{Quality Assurance}
\newacronym{jvm}{JVM}{Java Virtual Machine}

\begin{document}

\maketitle

\begin{abstract}
	%Sample IMRaD abstract: 
	Absence of correctly applied design principles triggers maintainability problems in software development and increases development cost. A tool for identification of design principle violations were developed using the design science methodology. The product was evaluated by testing on others code, using horizontal prototypes and having a workshop testing the product. 
	
	
	
\end{abstract}


\clearpage
\tableofcontents
\clearpage
\chapter{Introduction}

\todo{Ikke bruk for spesifikke begreper som ikke er definert i introduksjonen. Kan heller si litt mer generelt og om viktigheten, og så utdype mer i bakgrunnskapittelet.}

% https://student.unsw.edu.au/introductions - Nice resource for seeing what should be in the introdcution!

% State the general topic and give some background about its importance
Writing software that is easy to modify and extend is an important part of software engineering. Software that have this attribute (quality) is often referred to as maintainable. Non-maintainable software is often a breeding ground for bugs, refactoring\footnote{From Wikipedia: Process of restructuring existing code without changing its external behavior \cite{refactoring}.} tasks and technical debt\footnote{From Wikipedia: Concept in software development that reflects the implied cost of additional rework caused by choosing an easy (limited) solution now instead of using a better approach that would take longer \cite{technicalDebt}.}. Consequences include increased development time, inaccurate estimations causing lost deadlines and higher costs of introducing new developers to the project.

% Introduserer best practices etc. Low level code hjelp.
To help developers write code that is maintainable, well defined rules, best practices and conventions for writing code have been developed. The rules targets low-level code constructs, only covering small amounts of code. I will hereby, refer to these as \textit{rules}. % I will call these rules.

% Introduserer høyere nivås prinsipper som angriper på et høyere nivå
Less formal design principles that targets the structure or design of code at an architectural level have also been developed. The design principles are not formal and is often open for interpretation and subject for debate. Therefore, correct appliance of the principles often requires reasoning about the business domain and predicting future changes to the code base. % I will refer to these as principles

% Outline the current situation
Currently the rules are adopted by the programmers and can be enforced by the use of code-analysis. Tools for code-analysis have been developed and provides an effective way of checking rules, and can often auto-correct or provide solutions to detected problems.  

The design principles, on the other hand are mostly informal and therefore have limited support in tools for code-analysis. According to a pre-study on the current state on tools for improvement of code quality \cite{prestudy}, the tool support for detecting violations of design principles are very limited and suffer from false-positives that will create noise during development. Current approaches for detecting violations mostly involve manual code review, which is a time consuming and error-prone task.

% Identity the importance of the proposed research
Given the limitations in current approaches for detecting violation of design principles, more research is proposed. The importance of adhering to the design principles cannot be neglected as the architecture and design of code lay the foundation for further development. Restructuring badly designed code is a very time consuming task. By having tools help us adhere to the design principles, we can help ensure that correct design decisions are taken and possibly save large amounts of time.  

% Present the hypotheses and research questions
The hypotheses for this study are that there exists a way of using code review and code-analysis in new ways such that we can reduce the impact and disturbance of possible false-positives by presenting it in new ways and providing guidance or solutions to design issues. By following the design science methodology, a tool for detecting design principle violations will be developed and evaluated. 


%Writing maintainable and high quality code is an important part of software engineering. Various people define software maintainability differently, but a commonly accepted collection of quality attributes include extensibility, modularity, testability and understandability. To help developers write code with those attributes, well defined rules, best practices and conventions have been developed. They are often enforced by the use of tools commonly referred to as linters. Design principles is another invention that has been created to help developers write code that adheres to the aforementioned quality attributes. Unfortunately, many of the principles are not formal and is often open for interpretation and subject for debate. Therefore, correct appliance of the principles often requires reasoning about the business domain and predicting future changes to the code base. The absence of correctly applied design principles triggers maintainability problems and is often a breeding ground for bugs, refactoring\footnote{From Wikipedia: Process of restructuring existing code without changing its external behavior \cite{refactoring}.} tasks and technical debt\footnote{From Wikipedia: Concept in software development that reflects the implied cost of additional rework caused by choosing an easy (limited) solution now instead of using a better approach that would take longer \cite{technicalDebt}.}. Consequences include increased development time, inaccurate estimations causing lost deadlines and higher costs of introducing new developers to the project.



%Code analysis using tools, and code review are two techniques used that is used for detecting design issues or design principle violations in code. According to a pre-study on the current state on tools for improvement of code quality-study \cite{prestudy}, current tools are giving limited options for detecting design issues in code, and manual code reviews suffers from human failure.  \todo{sources that can help me argue that code review don't pick up everything.} By combining code analysis and manual code review the primary objective of the study is to see whether we can detect more design issues. Using the design science methodology an innovative product will be developed through short iterations that includes the use of prototypes and continuous feedback. The study will present the inner workings of the product as well as a detailed evaluation of the final artifact.

 %More specifically we will study which design principles that are eligible for code analysis and code review, how to reduce the amount of false-positives and how violations can be reported back to the developer.  


%Some tools offer analysis for detection of some design principle violations, but they suffer from false-positives and not being integrated into the development process - resulting in a high degree of context switching. 


The outline of the paper is as follows; Chapter \ref{background} gives some background information and an introduction to the topics maintainable code and code analysis. Chapter \ref{relatedwork} gives some insight in related work in the area. Chapter \ref{methodology} describes the methodology of the research process, and chapter \ref{results} presents the results, including the prototypes and the final artifact. Chapter \ref{discussion} discusses the results ending with the conclusion of the study.  

\chapter{Background}
\todo{watch out for self-plagiat. Diff with the pre-study when things starting to get fininished - smooth checker: https://copyleaks.com/compare .}
\label{background}
To see why achieving maintainable code is so important, and why a new tool for detecting design principle violations is suggested, we need some background information on what maintainable code is and how we can achieve it. The following sections will give a brief introduction to it.

\section{What is maintainable code?}
Software is a product that evolves over time and that continuously needs, fixes, features and updates according to the customer and users needs. To make the process of developing and maintaining a software product cheapest we need to ensure it meets certain requirements regarding quality. The software community is highly opinionated and software quality is measured differently based on (but not limited to) domain, programming language and business requirements. Therefore, measuring software quality and creating rules without exceptions is extremely hard. However, what we know is that the ratio of time spent reading versus writing code is well over 10 to 1 as Robert C. Martin states in \cite{Martin:2008:CCH:1388398}.

To reduce the amount of time spent on reading code (i.e understanding code), we need to ensure that the written code is understandable. We need to ensure that it is easy to understand what the code does and why it does what it does. It should be easy to locate what needs to change, easy to make changes and easy to ensure that the changes does not create unwanted side effects. \hfill 
\hfill \newline

More formally, developers have defined a set of quality attributes that will help ensure that the code is of high quality. A commonly accepted collection of quality attributes include extensibility, modularity, testability, understandability, performance, reliability and security. Martin Fowler did a useful distinction using the terms \textit{internal attributes} and \textit{external attributes} \cite{internalExternal}. The distinction is whether the attribute is visible for the user or customer. The internal quality attributes correspond to maintainability, that is our focus. 

Following are the definitions of the internal quality attributes with most importance in this study:
\begin{itemize}
	\item Extensibility - "Extensibility is a measure of the ability to extend a system and the level of effort required to implement the extension. Extensions can be through the addition of new functionality or through modification of existing functionality. The principle provides for enhancements without impairing existing system functions." \cite{Extensib83:online}
    	\item Modularity - "Modular programming is a software design technique that emphasizes separating the functionality of a program into independent, interchangeable modules, such that each contains everything necessary to execute only one aspect of the desired functionality." \cite{Modularp60:online}
	\item Testability - "Software testability is the degree to which a software artifact supports testing in a given test context. If the testability of the software artifact is high, then finding faults in the system (if it has any) by means of testing is easier." \cite{Software40:online}
	\item Understandability - "Understandability is defined as the attributes of software that bear on the users' (programmer) efforts for recognizing the logical concept and its applicability." \cite{Understa26:online}
\end{itemize}

In the next section we will look into methods of fulfilling these quality attributes.

\section{Achieving maintainable code}
To write code that is maintainable a set of concepts, principles and conventions including; Architectural patterns, design patterns, anti-patterns, design principles, metrics and best practices is used amongst developers. Some of them are well defined, and can easily be verified through source code analysis. Others are more abstract in nature and requires reasoning from the developers and is harder to verify.

An \textit{architectural pattern} is a general, reusable solution to a commonly occurring problem in software architecture within a given context \cite{architecturalpattern}. An example is the \gls{mvvm}-pattern for mobile development \cite{mvvm}. It is a well defined pattern and correct use or misuse could be verified through testing tools like ArchUnit \cite{archunit}. 

A \textit{design pattern} is similar to an architectural pattern, but more limited in scope. An example is the Adapter pattern \cite{Adapterp54:online}. Detection of design patterns is possible through mining \cite{TEKIN2014406}. The absence of patterns is harder to detect as the absence of a design pattern is not clearly defined.

Definitions of \textit{architectural anti-patterns} and \textit{design anti-patterns} have also been made. They are the exact opposite of architectural-patterns and design-patterns. In other words ways one should not solve a common problem. They are often called architecture-smells and design-smells. An example of architectural anti-pattern is the Cyclic Dependency \cite{cyclicdependency} and could be detected through dependency analysis. An example of design anti-pattern is the God-Object \cite{Godobjec14:online}, and is as stated about design patterns, not easily verifiable. However, metrics such as a high value of coupling and \gls{loc} could imply possible violations.


\textit{Design principles} are a set of guidelines that programmers should follow to avoid bad design. Because the design principles is of most importance in this study, a more in depth description is provided in section \ref{design-principles}.

\textit{Metrics} have been developed to measure how well one adheres to the design principles. Examples include cyclomatic complexity and coupling. \textit{Coupling} is the degree of interdependence between software modules \cite{Coupling2:online}. \textit{Cyclomatic complexity} is used to indicate the complexity of a program \cite{Cyclomat54:online}. They are easily calculated using code analysis.

\textit{Best practices} are informal rules that have been learned over time, or practice that have become part of the language ``culture''. The best practices can in some ways be equal to the design principles, but are often simpler and more limited in scope. Even if limited in scope, the range of different best practices is huge. Best practices includes but is not limited to, code patterns that are probable bugs, styling of code and readability. An example of best-practice in the Java language could be to use camel case (camelCase) \cite{camelcase} on variable-names, or to not have empty else-blocks. They are well defined and are verified using code analysis tools like SonarQube \cite{sonarqube}.

\section{Design principles}
\label{design-principles}
Design principles, also commonly referred to as programming principles, are a set of guidelines that programmers should follow to avoid bad design. According to Robert C. Martin \cite{robertcmartinprinciples} there are three characteristics of bad design that the design principles will help reduce:

\begin{enumerate}
	\item Rigidity - It is hard to change because every change affects too many other parts of the system.
	\item Fragility - When you make a change, unexpected parts of the system break.
	\item Immobility - It is hard to reuse in another application because it cannot be disentangled from the current application.
\end{enumerate}
A common set of design principles that often is referred to is the \gls{solid} principles \cite{solid}.

\begin{itemize}
    \item \gls{srp} -- "... states that every module or class should have responsibility over a single part of the functionality provided by the software, and that responsibility should be entirely encapsulated by the class, module or function." \cite{srp}
    \item \gls{ocp} -- "... states "software entities (classes, modules, functions, etc.) should be open for extension, but closed for modification"; that is, such an entity can allow its behaviour to be extended without modifying its source code." \cite{ocp}
    \item \gls{lsp} -- "Objects in a program should be replaceable with instances of their subtypes without altering the correctness of that program." \cite{lsp}
    \item \gls{isp} -- "... states that no client should be forced to depend on methods it does not use." \cite{isp}
    \item \gls{dip} --  "... states: \newline A. High-level modules should not depend on low-level modules. Both should depend on abstractions (e.g. interfaces). \newline
B. Abstractions should not depend on details. Details (concrete implementations) should depend on abstractions." \cite{dip}
\end{itemize}
    
As you can see, the design principles are often abstract and verification requires knowledge and reasoning about the business domain. For example, referring to the \gls{ocp}, how do you know what is going to be changed in the future, and how are you then going to design for extension? Making classes closed for modification of all changes is impossible and would clearly break the \gls{kiss} principle. And in case of \gls{srp}, how would you determine what is a single responsibility? 

To make matters worse; \gls{dip} suggests introducing abstractions to decouple software modules, while \gls{mimc} principle and \gls{kiss} principles says that introducing abstractions (e.g interfaces, abstract classes) introduces unwanted complexity.

The design principles are therefore hard to verify using code analysis. However, some principles are easier to verify than others, and signs of violation could be detected using code analysis or during code review which is described in section \ref{code-review}.

\section{Code analysis}
\todo{rewrite this to fit programming principles and PSI}
%Using code analysis and analyzing for design principles we can achieve maintainable code, which causes less rework and less context switches. 
To help developers of software systems adhere to the aforementioned concepts, principles and conventions, tools for code analysis have been developed. In code analysis we differentiate between two types of code analysis, dynamic code analysis and static code analysis. \textit{Dynamic code analysis} is done by analysing programs being executed on a processor, while \textit{static code analysis} is purely based on analysis of the source code. Since dynamic analysis is based on program execution it has the advantage of being able to measure the actual CPU, memory and energy performance of the application. 

%It can also gather information about the system that would be hard to detect using static code analysis. Examples include discovery of dynamic dependencies using reflection, or actual application usage. However, that does not mean that static code analysis is not able to target performance or dynamic aspects of source code.

As we search to improve the source code, we have chosen to focus on static code analysis. The static analysis is done by parsing the source code, creating an \gls{ast} and then analyzing the tree for violations of the aforementioned principles, concepts and conventions. Figure \ref{fig:ast} shows a simple example \gls{ast} where a static analysis tools could detect that the expression \texttt{x == 1} always evaluates to \texttt{true} and that the variable \texttt{y} is never used. The tool could then suggest that the branching is unnecessary and that the \texttt{y} variable is removed.  

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth/2]{report/images/ast.png}
	\caption{Simple \gls{ast} of x=1; if (x == 1) \{y = 10;\}}
	\label{fig:ast}
\end{figure}

In case of detekt-hint, to do analysis of the Kotlin \gls{ast} easier, Jetbrains\cite{jetbrains} have created an Open-Source \gls{psi} on top, adding utility methods for \gls{ast} analysis and modification. Figure \ref{fig:psi} shows a simplified example \gls{psi} that detekt-hint would use to find violations of \gls{isp}. The analysis would simply look in the PSI for classes that implement interfaces, and see if the overridden methods of that interface are empty or only throws exceptions. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{report/images/psi.png}
    \caption{Simplified version of a sample \gls{psi} showing a sign of violating the \gls{isp}}
    \label{fig:psi}
\end{figure}




\section{False positives and false negatives}
As stated above, most of the design principles are hard to detect violations of. Because we are not totally sure that sure that a design principle is violated and should be our tool will report violations, that isn't. We call these \textit{false-positives}. \todo{add a sample?}We often discuss the rate of false-positives, which is an important metric to evaluate the usefulness of different rules.

A \textit{false-negative} is when actual violation goes undetected. \todo{add sample?}

\todo{Should maybe use the wording "wrong guidelines" instead of false-positives in a way. }


\section{Code review}
\label{code-review}
Code review is a manual inspection process of looking through code. It is the most common way of finding design issues in code. Code review works very well if done correctly, but unfortunately it is easy get wrong, and is time consuming. 
% why it is easy to get wrong

It is a whole lot of things to consider when doing a code review. Naming a few;

\begin{itemize}
    \item Is the solution well architected? Is it following the architectural model of the application? Are all the files in the correct modules?
    \item Will changes cause unexpected behavior? 
    \item Is the code understandable? Does all variables, method names, classes express its intent?
    \item Is duplicate code introduced? Is this way of solving the problem the way we prefer it to be in this project?
\end{itemize}

When dealing with large amounts of changed code it is easy to forget some of these. Especially when dealing with repetitive tasks its easy to overlook issues. Tools should therefore help us by automating the most repetitive tasks, such that the time used is focused on finding real design issues. If we can find issues at the time of \gls{qa} the issue will be resolved much quicker because the developer does not need to context switch.

\section{Context switching}
\todo{Endre dette - context switching blir noe feil begrep. Disruptive refactoring? }
When developing, switching tasks is time consuming. 

\begin{quote}
    ``The trick here is that when you manage programmers, specifically, task switches take a really, really, really long time. That’s because programming is the kind of task where you have to keep a lot of things in your head at once. The more things you remember at once, the more productive you are at programming. A programmer coding at full throttle is keeping zillions of things in their head at once: everything from names of variables, data structures, important APIs, the names of utility functions that they wrote and call a lot, even the name of the subdirectory where they store their source code. If you send that programmer to Crete for a three week vacation, they will forget it all. The human brain seems to move it out of short-term RAM and swaps it out onto a backup tape where it takes forever to retrieve.'' \cite{human-context-switching}
\end{quote} 
If you exchange send to "Crete for three weeks" by fixing design issue (that needs to be resolved for further development) that was introduced one year ago, we can imagine the time to get into that context and resolving the issue. Or imagine maintaining a badly built software project that another group of developers built.


\chapter{Related work}
\label{relatedwork}
\todo{fill inn more stuff here}

To the best of my knowledge, a tool that only focuses on detecting violations of design principles does not exist. There exists a lot of tools for code analysis, \cite{}, \cite{} to name a few of the most used ones. Most of them support detection of violations of style conventions, best practices and finding possible bugs. However, some tools and linters include functionality for detecting violations on a small subset of the design principles. Therefore, developers need to adopt a large suite of tools to only be able to support detection of a few design principles violations. Also, the tools are fundamentally different and have different purpose and supports integration in the development process differently, both with its advantages and disadvantages. The tools are ranging from separate \gls{cli}s, native applications, online services, \gls{ide}s and \gls{ide} plugins. The purpose varies. Some are used for project level analysis activities, for finding areas in the codebase with issues, while other tools are focused at reporting issues at the time of writing or in the \gls{qa} process. I will elaborate on how the different tools support the different design design principles below.

The principle of \textbf{High Cohesion - Low Coupling} is a principle that has support in multiples tools, in the form of calculating a metric\footnote{A measurement of a particular characteristic of a program.}, including but not limited to JArchitect \cite{jarchitect} and CodeMR \cite{codemr}. JArchitect \cite{jarchitect} also includes functionality for visualizing  High Cohesion - Low Coupling using a \gls{dsm}. 

JArchitect uses the \gls{dsm} to find violations of \textbf{\gls{srp}} by looking at how many different types a class uses. Ndepend \cite{ndepend} calculates the \gls{lcom} value to find whether the class is cohesive or not, and therefore possibly breaking \gls{srp}. 

IntelliJ \cite{IntelliJ} (for Java) has support for detecting violations of the \textbf{\gls{lod}} principle.

Detecting similar snippets of code to find violations of the \textbf{\gls{dry}} principle is targeted by many tools including, but not limited to IntelliJ, PMD and Code Climate. However, code can violate \gls{dry} without looking similar, and tools that can detect such issues have not been found.  

% How i can use this information to my advantage , how is this useful?
By looking into which principles that currently are supported and how the different tools supports them,  selecting which design principles to support, and how to implement them has been easier.




\todo{Si mer om hvorfor jeg har valgt design science - 
legge struktur på vanlig utvikling. mer ordentlig enn utvikling med fokus på bruker. hvorfor design science: generelt bidrag ; ikke bare om produktet løser problemet for kotlin utviklere. mer evaluering, og om "hinting" er interessant for alle utviklere. }

\todo{diff between design science and development - google dette}




\chapter{Methodology}
\label{methodology}
\todo{rephrase}
The development of a system for detecting design principle violation may look as any user-centred design process. However, there are two general goals of this study. The first is to build an innovative software product. The second goal is to develop knowledge about giving guidelines on following design principles, in a developer workflow. To reach the second goal  Such that this knowledge can be used to develop similar tools, or be further built upon. To develop such knowledge, a methodology presented in (A Design Science Research Methodology for Information Systems Research) \cite{10.2753/MIS0742-1222240302} will be utilized. The methodology provides specific guidelines for evaluation and iteration in research projects. 

The knowledge is presented in the form of this whole thesis, while the actual product. 

Design science is a research methodology that focuses on getting knowledge about a domain through development of innovative artifacts. The methodology provides specific guidelines for evaluation and iteration in research projects. 

For this thesis it is selected because it 



It is selected because it fits the process of building a innovative software artifact. The software artifact will be created through a series of iterations that include the follow activities; problem identification/understanding and motivation, definition of objectives for a solution, design and development, demonstration/testing, evaluation, communication. Figure \ref{fig:designScience} is taken from Peffers. K \cite{Peffers2007ADS} and shows the process of the design science methodology. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{report/images/designScience.png}
    \caption{The process of the design science research methodology}
    \label{fig:designScience}
\end{figure}



As can be seen in the figure is important to notice that the activities is not done in any particular order, but in that order as seen required. I will elaborate on how the different activities is applied to the project below. 



\section{Problem identification and motivation}
Absence of correctly applied design principles triggers maintainability problems and is often a breeding ground for bugs, refactoring tasks and technical debt. Finding design flaws as soon as possible is a crucial task to limit the amount of rework required. There are mainly two reasons for this: 

\begin{enumerate}
    \item Building upon badly designed software further complicates and increases the difficulty of fixing the software.

    \item The developer is in the context of the current code. Fixing design flaws as soon as possible would require less time to do because the developer knows the context and does not need to context switch.

\end{enumerate}

\todo{Definere hva jeg mener med "detection of violations". Det er mer "steder å hinte på" eller guidelines for å følge designprinsipper. }

There are mainly two techniques for detecting design issues, code-analysis using tools and manual code-review. Some code-analysis tools offer design principle analysis as mentioned in section \ref{relatedwork}, but suffer from limited functionality regarding design principles and not being integrated into the development process. Therefore, manual code review is the main arena where most design-issues are found. Finding design issues through code review is time-consuming and requires deep understanding of the problem that is being resolved. This process is prone to errors and overlooking due to the nature of human failure. Having a tool that could help this process would help both the reviewer and the reviewee with not overlooking possible design issues, and could cause useful design discussions within the team.

\todo{litt for teknisk problem, hvordan presentere det for brukeren uten å gjøre utvikleren irritert? Hvordan presentere dette for brukeren i en utviklingsprosess?}
\todo{savner hvordan skal dette passe inn i en utviklings prossess?}
\hfill \newline
This problem identification raises an important question which is my main research question:
\hfill \newline
\hfill \newline
\textbf{RQ1}: How can one use techniques for detecting design principle violations to improve the maintainablity of code? \newline
\textbf{RQ1.1}: Which design principles can be verified using code analysis? \newline
\textbf{RQ1.2}: How to deal with a high rate of false-positives? 


\section{Define objectives of a solution}
\label{objectives-of-solution}


\todo{Write some more details about the OS?, mer generelt. Ikke si noe om løsning. }
\todo{Trenger en ide om hvor sikker analysen er. }
Initially the objectives of a solution had the following characteristics:

\begin{itemize}
    \item [\textbf{OS1:}] It detects violations of design principles through a set of rules using static code analysis.
    \item [\textbf{OS2:}] False-positives should not create too much noise in the developer workflow. First, the rate of false positives should be reduced as much as possible. Second, reported violations should be easy to ignore. 
    \item [\textbf{OS3:}] It contributes to detecting design issues at the time of \gls{qa}.
    
    \todo{hvor kommer de spesifikke løsningene fra, kan få det fra background, eller så må det være mer generelle objectives.}
    \todo{fjerne mekanismen og hvordan det er løst}
    \item [\textbf{OS4:}] It should be configurable for defining desired threshold values and turning off unwanted rules.
    \item [\textbf{OS5:}] Focus on building an artifact that can either be included into existing tools or is easy to integrate with existing tools so that adoption of the tool is easy.
\end{itemize}

The objectives were confirmed by the initial prototype that were posted on social media. 



During development of the vertical prototype it came to mind that reported violations should include context of the code (referring to actual constructs in the code) to ease the process of deciding if a detection is a true- or false-positive or to help with the solution. It also appeared harder than initially thought to create and develop accurate rules. A new objective and a specification of OS1 was therefore made: 


\begin{itemize}
    \item [\textbf{OS6:}] Reported violations includes code context to ease the process of deciding if it is a true- or false-positive. 
    \item [\textbf{OS1.1:}] It detects violations of \textbf{important} design principles through a \textbf{limited} set of rules using static code analysis.
\end{itemize}

Later on, it was discovered that the performance and ease of setup are crucial objectives to make developers adopt the tool. Therefore, two new objectives for a solution was defined:
\begin{itemize}
     \item [\textbf{OS7:}] It is easy to set up and use for all team members in the project
    \item [\textbf{OS8:}] Good performance
\end{itemize}




%It all boils down to time=\$. The tool will only provide value of we can save development time using it. Then, if the sum of time saved by finding design issues earlier is more than the sum of the negative impact of considering the false-positives, the tool will provide value.
%As a general objective we can say that, the tool will provide value if the value of detecting true-positives is worth more than the negative impact of all the false-positives. 
%However, to measure the time spared by detecting issues earlier is an impossible task to measure, but we know that it is quite


Rule specific objectives: 
Comments are understandable, and provides suggestions for solutions.

\section{Design and development}
\todo{krevende brukergrupee, som kan kreve funksjonalitet, og ikke en fasade og se at dette kan bli et virkelig produkt. Derfor ble vertikal prototype utviklet først. }
\todo{Si at en horizontal prototype kan være vanlig å utvikle først, men at dette ble gjort annerledes i dette prosjektet pga pga.}

% Generally about design and development
The design and development phase involves the development of vertical- and horizontal prototypes, with high and low resolution, as well as the final artifact. 

% Theory about prototypes
\textit{Horizontal prototypes} covers a broad view of the entire system and focuses more on user interaction with the system, rather than low level details. \textit{vertical prototypes} on the other hand focuses on the technical challenges and a single functionality of the system. Depending on the precision, or how much it looks and works like the finished product, it is either a \textit{low resolution} or \textit{high resolution prototype}. 

First, low resolution prototypes will be created, and then more high resolution prototypes. The reason is that we want to get feedback on the initial idea as quick as possible and to adjust the product accordingly.

% About the design and development phase in this project?




%Used a prototype of the horizontal prototype to verify if i got feedback on what i wanted to. (Test on Eirik) \todo{write this one}

 
 
\section{Demonstration}
\todo{Because hard to get informants & corona: Shifted focus on getting feedback trough creating PR on github, to get real projects to test the tool.?}

The next logical step after developing a prototype is to demonstrate and test it. Depending on the prototype created, different forms of demonstration will be used. The most important aspect of demonstrating the prototypes, is to put them in a environment that is as similar as possible to the environment that the final product will be used in, a so called field test. This involves getting users to test the product. However, solutions that does not involve explicit testing and field testing must also be considered as gathering participants for testing could be time consuming and require more resources.  
 
\section{Evaluation}
Continuous evaluation of the prototypes and the developed artifact is important to adjust the product to the users needs. Different types of evaluation methods includes qualitative methods and quantitative methods, both formal and informal. More specifically, interest measurement, unstructured and informal discussions with other developers, colleges, professors and friends, semi structured interviews, presentations, prototype testing and workshops. Informal methods and events are easier to organize and can inspire to useful discussions, possible features and useful feedback. Formal demonstrations are better for structured feedback and to find the overall results instead of single users perspective. By using both of the strategies we can get the best of both worlds. The results from the evaluations is presented in the results.

\section{Communication}
The end result is communicated through this master thesis. Product is also available is for use and further development at https://github.com/Mkohm/detekt-hint/.

\chapter{Results}
\label{results}
Describing the exact number of iterations and the iteration steps is not possible as one continuously evaluates the product and adjusts the product under development. But seeing the development process in a big picture we can approximately look at 4 iterations in the design science methodology. A visualization of the general process can be seen in figure \ref{fig:workflow}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{../images/workflow.png}
    \caption{The general process of developing the final artifact}
    \label{fig:workflow}
\end{figure}

The 4 iterations were focused on 4 different versions of the product. The different versions are described and their evaluation are described in the next sections. The results are presented it the order they were achieved, making the next section a result of the previous one.

\section{Initial prototype}

\subsection*{Why and how it was created}
An initial low resolution prototype was created to see if there was any interest in a tool for detecting design principle violations. The prototype can be seen in figure \ref{fig:mockup}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{../images/demo.png}
    \caption{Initial prototype that was presented on social media}
    \label{fig:mockup}
\end{figure}

\subsection*{Demonstration}
The initial prototype was posted on the subforum of Kotlin\cite{kotlin-reddit} and SoftwareArchitecture\cite{softwarearch-reddit} on Reddit. Additionally, the prototype was presented and discussed with friends. 

\subsection*{Evaluation}
The general feedback was that there was an interest in a tool like this, and that it would be worth spending more time on. This is only based on a few comments and a fair amount of upvotes on the post, so the actual value of that evaluation will be limited. Read more about this in \ref{flaws-of-study}. In both subforums, the post received an amount of upvotes that made the post "top this week" in under 12 hours. \\

Suggestions for improvement included: 
\begin{itemize}
    \item Do not claim that the developer is wrong when there can be a lot of false-positives, instead present it as this \textbf{might} be a violation of a design principle.
    \item Identifications could create useful discussions within the developer team.
    \item Focus on removing the amount of false-positives as much as possible and making it configurable to fit different needs.
\end{itemize}

In general the feedback confirmed my initial objectives for a solution.

\section{Vertical prototype}

\subsection*{Why and how it was created}
The initial prototype proposed more work into creating a tool for detecting design principle violations. Normally, a vertical prototype is built first, with the intention of getting an idea of which features that needs to be implemented and the priority of those. In this case a vertical prototype was built first for three reasons:

\begin{enumerate}
    \item The prioritization is somewhat known up front. Being a product focusing on detection of design principle violations, it is quite natural that the product should prioritize principles that are not covered by other tools and that the most significant principles are considered first.
    \item Too see if building a tool for detecting design principle violations is a feasible task within the scope of a master thesis.
    \item Developers tend to be more interested in technical solutions that is working than non-interactive prototypes. Getting feedback on the following horizontal prototype would be easier if actual solutions to technical problems could be presented.
\end{enumerate}

% How the prototype was created
Before building the prototype an in depth investigation of different approaches was done. The tool would ideally support multiple languages, but to limit the scope and because of interest and knowledge about Kotlin and its ecosystem, it was selected as the language subject for analysis. Several tools/framework was considered to use as the fundament for a tool, including Ktlint and Code Climate, but Detekt was chosen as the best platform to build on because it looked as a promising alternative for fulfillment of the objectives of a solution described in \ref{objectives-of-solution}.

\subsection*{Demonstration}
The prototype was mainly demonstrated continuously during development to the developer. It was also partly presented to the participants at the detekt-hint presentation.

\subsection*{Evaluation}

By building upon Detekt the objectives are solved in this way:
\begin{itemize}
    \item [\textbf{OS1:}] It enables writing detection-rules by analysis of the Kotlin \gls{ast} and Jetbrains \gls{psi}.
    
    \item [\textbf{OS2:}] Writing rules with high accuracy using the detekt-api, the amount of false positives can be held to a minimum. Through the danger-kotlin\_detekt plugin violations can be posted on \gls{pr}, minimizing noise and impact of possible false-positives.
    
    \item [\textbf{OS3:}] Through commenting on \gls{pr}'s the design issues is targeted at the time of \gls{qa}.
    
    \item [\textbf{OS4:}] Provides configuration options for rules through the use of a configuration file so the rules can be configured to fit developers/teams best.
    
    \item [\textbf{OS5:}] Easy to use with detekt, as the developed tool is a detekt plugin.
    
    \item [\textbf{OS6:}] Code context can easily be added to comments.
    
    \item [\textbf{OS7:}] Is made extensible through the development of detekt plugins and is easily added to any project already using detekt, and does not require any setup from individual developers.

    \item [\textbf{OS8:}] Have good performance and rules can run in parallel. 
\end{itemize}

Detekt is also open-source, making it easy to get in touch with the developers if any issues or problems occur.


The prototype therefore solves many of the objectives of a solution. However, because of being a prototype it only supports 1 rule that has too many false positives, and the comment is not helping the developer.


Building the prototype confirmed the above, and showed a simple rule in action. It was therefore a successful prototype that was a proof of concept and laid the foundations to further development. What was learned developing the prototype is that creating rules is an time-intensive process because it involves programming in a complex environment with a huge API with lack of documentation. In addition, creating inspections for programming languages involves handling a lot of edge-cases that can take time to cover. Writing test cases for all the different scenarios ensured proper handling of all the edge-cases.


The main takeaways from evaluating the prototype:
\begin{itemize}
    \item Detekt is a good platform for building such a tool and enables fulfillment of most objectives for a solution
    \item Further development should focus on a small set of the most important rules, because they can take a long time to implement.
    \item Run the tool on others code to find possible bugs and false-positives
\end{itemize}

\section{Horizontal prototype}
\subsection*{Why and how it was created}
As the vertical prototype showed; a limited number of rules have to be supported. That raised the question of which rules to implement. Looking through a lot of principles, i tried to determine which rules that would be useful. Since \gls{solid} is considered by many to be the most important design principles, the focus was put on those. The process ended by creating the horizontal prototype that included the rules that i had the most value. 


The horizontal prototype was built by creating sample \gls{pr} in a sample repository on Github\cite{sample-repository}, and then commenting on the \gls{pr}'s with the bot user. An example from the prototype is presented in figure \ref{fig:liskov}.

\subsection*{Demonstration}
The horizontal prototype was then presented for a group of x number of people using a semi structured interview. The interview followed the semi-structured interview schema that can be found in the appendix \cite{}. The horizontal prototype was also presented for approximately 20 participants of Javabin Trondheim\footnote{A usergroup for persons interested in sofware development on the Java and \gls{jvm} platform, and related technologies.} to gather additional informants and feedback. the system (javabin). 


\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{../images/demo.png}
    \caption{Screenshot of horizontal prototype - Showing the composition over inheritance / \gls{lsp} rule}
    \label{fig:liskov}
\end{figure}


% What did i find when using this prototype? What changes does the product need, or does it confirm that i am on the right path?

\subsection*{Evaluation}

The schema used for the semi-structured interview, the participants answers/feedback and selected images of the prototype can be found in appendix \ref{horizontal-prototype}. The full prototype can be found in the sample repository \cite{sample-repository}. 

Does not need a diagram, can use text instead?

Because it was discovered that a small subset of rules only could be developed, it was then a question of finding out which rules should be implemented. Therefore the horizontal prototype was created.


Outcome:


\section{Final artifact}
\subsection*{Why and how it was created}
The final artifact is a continuation of the work done in the vertical prototype, and hence has the same qualities and ways of solving the objectives of a solution. A more technical in depth description of the final artifact is found in section \ref{technical-solution}. 


\subsection*{Demonstration}
Through a workshop the final artifact was evaluated. Analysis of pull requests and see if we can find some issues.
Schema:
Who is the participants, some background information on them. What did the participants say. What is the takeaway from the workshop? What did i change in the product after having the workshop? Because of difficulties related to finding informants, i had to focus on evaluating the prototype by myself, and gethering numbers for how many 

\subsection*{Evaluation}
\begin{itemize}
    \item false-positive rate / per rule
    \item how many comments per PR avg? How obtrusive is the tool
\end{itemize}

What is the goal, how should i reach the goal of the workshop. Keep the workshop structured.


Gather a group of Kotlin/Android entusiasts for a workshop where one could order pizza and code using this tool. Focus on feedback. Could for example analyze some code that they know and give some feedback on whether it is useful or not. What would have been useful?


\section{Technical solution}
\label{technical-solution}
\subsubsection{Detekt-hint specification}
Specification of all the rules.

\subsubsection{Detekt-hint}

\subsubsection{Architecture}
A diagram of how everything interacts with each other.

\subsubsection{Detekt}
Detekt is a static analysis tool for kotlin. Which provides access to a framework for rule creating for analyzing code and reporting warnings.

Detekt gives us access to IntelliJ PSI for analyzing Kotlin code. The PSI is built on top of the \gls{ast} provided by the kotlin compiler, and provides utility methods for modifying and querying of the underlying \gls{ast}.

Type resolution?

\subsubsection{Detekt-hint}
Final source code can be found on Github\cite{detekt-hint-repository}

\subsubsection{Danger}

\subsubsection{Danger detekt plugin}

\chapter{Discussion and conclusion}
\label{discussion}

\section{Discussion}

\section{Future work}
Look at the evaluation results and fix/work on all of those! 
Implement more rules. More accuraty calculations of LCOM. Considering the different types of LCOM values and choose the best one.
Reducing the amount of false positives.
Announce the tool so more developers would use it.

Providing more context and/or possible solutions in the comments. Images or graphs explaining.
Increasing the performance.
Easing the setup process. Github app? Direct integration with the repository with no setup. A tool like code-climate that does not need any configuration. Plus of tool like this: all setup is in source control. Downside: could be tedious to set up or not all team members want to use it.
\section{Flaws of the study}
\label{flaws-of-study}
not enough informants - lack of testing the software
informants lacking knowldge about design principles
Should create samples for the horizontal prototype that demonstrates possible false positives as well as true positives. Kan gi inntrykk av at programmet er lurere enn det egentlig er siden jeg bare presenterte de positive identifikasjonene. Inntrykk av interesse på reddit kan være feil pga dette.

\section{Conclusion}
\label{conclusion}

\section{Acknowledgements}
\label{acknowledgements}
Thanks to supervisor, all participants in workshop and prototype sessions.

\printbibliography

\appendix
\label{appendix}
\input{appendix.tex}
\end{document}