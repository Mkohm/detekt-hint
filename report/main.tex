\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[acronym]{glossaries}
\usepackage{biblatex}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{graphicx}
\usepackage{pgfplots}
\usepackage{fancyvrb}

\addbibresource{bibliography.bib}


\title{Detekt-hint -- Detection of design principle violations}
\author{Marius Kohmann}
\date{June 2020}


\newacronym{ast}{AST}{Abstract Syntax Tree}
\newacronym{solid}{SOLID}{\textbf{S}ingle responsibility, \textbf{O}penâ€“closed, \textbf{L}iskov substitution, \textbf{I}nterface segregation, \textbf{D}ependency inversion}
\newacronym{dry}{DRY}{Don't Repeat Yourself}
\newacronym{srp}{SRP}{Single Responsibility Principle}
\newacronym{ocp}{OCP}{Open-Closed Principle}
\newacronym{lsp}{LSP}{Liskov Substitution Principle}
\newacronym{isp}{ISP}{Interface Segregation Principle}
\newacronym{dip}{DIP}{Dependency Inversion Principle}
\newacronym{lcom}{LCOM}{Lack of Cohesion Of Methods}
\newacronym{loc}{LOC}{Lines Of Code}
\newacronym{mvvm}{MVVM}{Model-View-ViewModel}
\newacronym{pr}{PR}{Pull Request}
\newacronym{ntnu}{NTNU}{Norwegian University of Science and Technology}
\newacronym{mimc}{MIMC}{More Is More Complex}
\newacronym{kiss}{KISS}{Keep It Simple Stupid}

\begin{document}

\maketitle

\begin{abstract}
	%Sample IMRaD abstract: 
	
	
	
\end{abstract}


\clearpage
\tableofcontents
\clearpage
\section{Introduction}

% Why maintainable code is important
Writing maintainable and high quality code is an important part of software engineering. Various people define software maintainability differently, but a commonly accepted collection of quality attributes include extensibility, modularity, testability and understandability. To help developers write code with those attributes, well defined rules and conventions have been developed. They are often enforced by the use of tools commonly referred to as linters. Design principles is another invention that has been created to help developers write code that adheres to the aforementioned quality attributes. Unfortunately, many of the principles are not formal and is often open for interpretation and subject for debate. Therefore, correct appliance of the principles often requires reasoning about the business domain and predicting future changes to the code base. The absence of correctly applied design principles triggers maintainability problems and is often a breeding ground for bugs, refactoring\footnote{From Wikipedia: Process of restructuring existing code without changing its external behavior \cite{refactoring}.} tasks and technical debt\footnote{From Wikipedia: Concept in software development that reflects the implied cost of additional rework caused by choosing an easy (limited) solution now instead of using a better approach that would take longer \cite{technicalDebt}.}. Consequences include increased development time, inaccurate estimations causing lost deadlines and higher costs of introducing new developers to the project.

Code analysis using tools, and code review are two techniques used for detecting design issues or design principle violations in code. According to a pre-study on the current state on tools for improvement of code quality-study \cite{prestudy}, current tools are giving limited options for detecting design issues in code, and manual code reviews suffers from human failure.  \todo{sources that can help me argue that code review don't pick up everything.} By combining code analysis and manual code review the primary objective of the study is to see whether we can detect more design issues. Using the design science methodology an innovative product will be developed through short iterations that includes the use of prototypes and continuous feedback. The study will present the inner workings of the product as well as a detailed evaluation of the final artifact.

 %More specifically we will study which design principles that are eligible for code analysis and code review, how to reduce the amount of false-positives and how violations can be reported back to the developer.  


%Some tools offer analysis for detection of some design principle violations, but they suffer from false-positives and not being integrated into the development process - resulting in a high degree of context switching. 

% Code review
%Manual process of inspecting code are error-prone, suffers from "large pr syndrome" and the fact that different developers apply the design principles differently.


The outline of the paper is as follows; Section \ref{background} gives some background information and an introduction to the topics of writing code with high quality and code analysis. Section \ref{methodology} describes the methodology of the research process. Section \ref{relatedwork} gives some insight in related work in the area and section \ref{results} presents the developed artifact, and a detailed evaluation of it. Section \ref{discussion} discusses the results, and lastly in section \ref{conclusion} we conclude the study.  

\section{Background}
\todo{watch out for self-plagiat. Diff with the pre-study when things starting to get fininished - smooth checker: https://copyleaks.com/compare .}
\label{background}
To see why achieving maintainable code is so important, and why a new tool for detecting design principle violations is suggested, we need some background information on what maintainable code is and how we can achieve it. The following sections will give a brief introduction to it.

\subsection{What is maintainable code?}
Software is a product that evolves over time and that continuously needs, fixes, features and updates according to the customer and users needs. To make the process of developing and maintaining a software product cheapest we need to ensure it meets certain requirements regarding quality. The software community is highly opinionated and software quality is measured differently based on (but not limited to) domain, programming language and business requirements. Therefore, measuring software quality and creating rules without exceptions is extremely hard. However, what we know is that the ratio of time spent reading versus writing code is well over 10 to 1 as Robert C. Martin states in \cite{Martin:2008:CCH:1388398}.

To reduce the amount of time spent on reading code (i.e understanding code), we need to ensure that the written code is understandable. We need to ensure that it is easy to understand what the code does and why it does what it does. It should be easy to locate what needs to change, easy to make changes and easy to ensure that the changes does not create unwanted side effects. \hfill 
\hfill \newline

More formally, developers have defined a set of quality attributes that will help ensure that the code is of high quality. A commonly accepted collection of quality attributes include extensibility, modularity, testability, understandability, performance, reliability and security. Martin Fowler did a useful distinction using the terms \textit{internal attributes} and \textit{external attributes} \cite{internalExternal}. The distinction is whether the attribute is visible for the user or customer. The internal quality attributes correspond to maintainability, that is our focus. 

Following are the definitions of the internal quality attributes with most importance in this study:
\begin{itemize}
	\item Extensibility - "Extensibility is a measure of the ability to extend a system and the level of effort required to implement the extension. Extensions can be through the addition of new functionality or through modification of existing functionality. The principle provides for enhancements without impairing existing system functions." \cite{Extensib83:online}
    	\item Modularity - "Modular programming is a software design technique that emphasizes separating the functionality of a program into independent, interchangeable modules, such that each contains everything necessary to execute only one aspect of the desired functionality." \cite{Modularp60:online}
	\item Testability - "Software testability is the degree to which a software artifact supports testing in a given test context. If the testability of the software artifact is high, then finding faults in the system (if it has any) by means of testing is easier." \cite{Software40:online}
	\item Understandability - "Understandability is defined as the attributes of software that bear on the users' (programmer) efforts for recognizing the logical concept and its applicability." \cite{Understa26:online}
\end{itemize}

In the next section we will look into methods of fulfilling these quality attributes.

\subsection{Achieving maintainable code}
To write code that is maintainable a set of concepts, principles and conventions including; Architectural patterns, design patterns, anti-patterns, design principles, metrics and best practices is used amongst developers. Some of them are well defined, and can easily be verified through source code analysis. Others are more abstract in nature and requires reasoning from the developers and is harder to verify.

An \textit{architectural pattern} is a general, reusable solution to a commonly occurring problem in software architecture within a given context \cite{architecturalpattern}. An example is the \gls{mvvm}-pattern for mobile development \cite{mvvm}. It is a well defined pattern and correct use or misuse could be verified through testing tools like ArchUnit \cite{archunit}. 

A \textit{design pattern} is similar to an architectural pattern, but more limited in scope. An example is the Adapter pattern \cite{Adapterp54:online}. Detection of design patterns is possible through mining \cite{TEKIN2014406}. The absence of patterns is harder to detect as the absence of a design pattern is not clearly defined.

Definitions of \textit{architectural anti-patterns} and \textit{design anti-patterns} have also been made. They are the exact opposite of architectural-patterns and design-patterns. In other words ways one should not solve a common problem. They are often called architecture-smells and design-smells. An example of architectural anti-pattern is the Cyclic Dependency \cite{cyclicdependency} and could be detected through dependency analysis. An example of design anti-pattern is the God-Object \cite{Godobjec14:online}, and is as stated about design patterns, not easily verifiable. However, metrics such as a high value of coupling and \gls{loc} could imply possible violations.


\textit{Design principles} are a set of guidelines that programmers should follow to avoid bad design. Because the design principles is of most importance in this study, a more in depth description is provided in section \ref{design-principles}.

\textit{Metrics} have been developed to measure how well one adheres to the design principles. Examples include cyclomatic complexity and coupling. \textit{Coupling} is the degree of interdependence between software modules \cite{Coupling2:online}. \textit{Cyclomatic complexity} is used to indicate the complexity of a program \cite{Cyclomat54:online}. They are easily calculated using code analysis.

\textit{Best practices} are informal rules that have been learned over time, or practice that have become part of the language ``culture''. The best practices can in some ways be equal to the design principles, but are often simpler and more limited in scope. Even if limited in scope, the range of different best practices is huge. Best practices includes but is not limited to, code patterns that are probable bugs, styling of code and readability. An example of best-practice in the Java language could be to use camel case (camelCase) \cite{camelcase} on variable-names, or to not have empty else-blocks. They are well defined and are verified using code analysis tools like SonarQube \cite{sonarqube}.

\subsection{Design principles}
\label{design-principles}
Design principles, also commonly referred to as programming principles, are a set of guidelines that programmers should follow to avoid bad design. According to Robert C. Martin \cite{robertcmartinprinciples} there are three characteristics of bad design that the design principles will help reduce:

\begin{enumerate}
	\item Rigidity - It is hard to change because every change affects too many other parts of the system.
	\item Fragility - When you make a change, unexpected parts of the system break.
	\item Immobility - It is hard to reuse in another application because it cannot be disentangled from the current application.
\end{enumerate}
A common set of design principles that often is referred to is the \gls{solid} principles \cite{solid}.

\begin{itemize}
    \item \gls{srp} -- "... states that every module or class should have responsibility over a single part of the functionality provided by the software, and that responsibility should be entirely encapsulated by the class, module or function." \cite{srp}
    \item \gls{ocp} -- "... states "software entities (classes, modules, functions, etc.) should be open for extension, but closed for modification"; that is, such an entity can allow its behaviour to be extended without modifying its source code." \cite{ocp}
    \item \gls{lsp} -- "Objects in a program should be replaceable with instances of their subtypes without altering the correctness of that program." \cite{lsp}
    \item \gls{isp} -- "... states that no client should be forced to depend on methods it does not use." \cite{isp}
    \item \gls{dip} --  "... states: \newline A. High-level modules should not depend on low-level modules. Both should depend on abstractions (e.g. interfaces). \newline
B. Abstractions should not depend on details. Details (concrete implementations) should depend on abstractions." \cite{dip}
\end{itemize}
    
As you can see, the design principles are often abstract and verification requires knowledge and reasoning about the business domain. For example, referring to the \gls{ocp} and \gls{srp}, how do you know what should be designed for extension? And how would you determine what is a single responsibility? 

To make matters worse; \gls{dip} suggests introducing abstractions to decouple software modules, while \gls{mimc} principle and \gls{kiss} principles says that introducing abstractions (e.g interfaces, abstract classes) introduces unwanted complexity.

The design principles are therefore hard to verify using code analysis. However, some principles are easier to verify than others, and possible violations could be detected using code analysis.

\subsection{Code analysis}
\todo{rewrite this to fit programming principles and PSI}
%Using code analysis and analyzing for design principles we can achieve maintainable code, which causes less rework and less context switches. 
To help developers of software systems adhere to the aforementioned concepts, principles and conventions, tools for code analysis have been developed. In code analysis we differentiate between two types of code analysis, dynamic code analysis and static code analysis. \textit{Dynamic code analysis} is done by analysing programs being executed on a processor, while \textit{static code analysis} is purely based on analysis of the source code. Since dynamic analysis is based on program execution it has the advantage of being able to measure the actual CPU, memory and energy performance of the application. 

%It can also gather information about the system that would be hard to detect using static code analysis. Examples include discovery of dynamic dependencies using reflection, or actual application usage. However, that does not mean that static code analysis is not able to target performance or dynamic aspects of source code.

As we search to improve the source code, we have chosen to focus on static code analysis. The static analysis is done by parsing the source code, creating an \gls{ast} and then analyzing the tree for violations of the aforementioned concepts and conventions. Figure \ref{fig:ast} shows a simple example \gls{ast} where a static analysis tools could detect that the expression \texttt{x == 1} always evaluates to \texttt{true} and that the variable \texttt{y} is never used. The tool could then suggest that the branching is unnecessary and that the \texttt{y} variable is removed.  

\todo{Exchange this for an example with useCompositionInsteadOfInheritance rule}
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth/2]{report/images/ast.png}
	\caption{Simple \gls{ast} of x=1; if (x == 1) \{y = 10;\}}
	\label{fig:ast}
\end{figure}



\subsection{False positives}
As stated above, some rules are hard to verify and is the reason why very few tools cover them. Because we could not be 100\% sure if a design principle is followed we would end up with our tool reporting issues, that in reality are not issues. We call these \textit{false-positives}. These create noise and are obtrusive for the developer, so it is important to keep the false-positive rate as low as possible. 


\subsection{Code review}
What is wrong with manual code review?

... should detect most issues now, and not wait for later so that context switching is not needed.

What code review is, and its plusses and minuses.

\subsection{Context switching}
start with something to do.
then do it.
code is continously linted.
manual quality assurance. Things can and will slip through. Should catch design issues here. Design issues slipping through has a high cost of fixing later due to lost context. If the developer is able to fix the design issue at the time of QA the issue will be resolved much quicker because of having the context.

\begin{quote}
    ``The trick here is that when you manage programmers, specifically, task switches take a really, really, really long time. Thatâ€™s because programming is the kind of task where you have to keep a lot of things in your head at once. The more things you remember at once, the more productive you are at programming. A programmer coding at full throttle is keeping zillions of things in their head at once: everything from names of variables, data structures, important APIs, the names of utility functions that they wrote and call a lot, even the name of the subdirectory where they store their source code. If you send that programmer to Crete for a three week vacation, they will forget it all. The human brain seems to move it out of short-term RAM and swaps it out onto a backup tape where it takes forever to retrieve.''
\end{quote}
\cite{human-context-switching}



\subsection{Design science}
Design science is a research methodology that focuses on getting knowledge through development of innovative artifacts. The methodology provides specific guidelines for evaluation and iteration in research projects.

https://medium.com/@pello/design-science-research-a-summary-bb538a40f669
\todo{insert image of design science methodology}

\subsubsection{Prototyping}

horizontal and vertical prototypes. high and low res prototypes.
Used a prototype of the horizontal prototype to verify if i got feedback on what i wanted to. (Test on Eirik)


\subsubsection{MVP}
develop the least neccesary for having a working product.



\section{Related work}
\label{relatedwork}
Ndepend. Jarchitect. 

\section{Methodology}
\label{methodology}
This study will follow the Design Science methodology which is presented in (A Design Science Research Methodology for Information Systems Research) \cite{10.2753/MIS0742-1222240302}. It is selected because it fits the process of building a innovative software artifact. The software artifact will be created through a series of iterations that include the follow activities; problem identification/understanding and motivation, definition of objectives for a solution, design and development, demonstration/testing, evaluation, communication. Figure \ref{fig:designScience} is taken from Peffers. K \cite{Peffers2007ADS} and shows the process of the design science methodology. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{report/images/designScience.png}
    \caption{The process of the design science research methodology}
    \label{fig:designScience}
\end{figure}



As can be seen in the figure is important to notice that the activities is not done in any particular order, but in that order as seen required. I will elaborate on how the different activities is applied to the project below. 



\subsection{Problem identification and motivation}

% Problem identification
The problem is that important design decisions are'nt considered before it is too late, so that bad design end up in production code, creating maintainability problems.


The problem is that very few tools for detecting design principle violations exists. As mentioned in \ref{relatedwork}, the existing tools analyze the whole codebase and is not integrated with the development process. Using the existing tools can be good for project level analysis activities, and finding areas of improvement. The tools also lack support for many import design principles.


What Detekt-hint is looking to improve is the tight integration with the development process and helping the developer taking good decisions while the developer is in the context.


\hfill \newline
These two goals can be summarized as two research questions:
\hfill \newline
\hfill \newline
\textbf{RQ1}: How can one use techniques for detecting violation of design principles to improve the maintainablity of code? \newline
\textbf{RQ1.1}: Which design principles can be verified using code analysis? \newline
\textbf{RQ1.2}: How to deal a higher rate of false-positives? 


Is the value of a true-positive worth more than the sum of all the false-positives? It all boils down to time=money. Time to overlook times the amount of false-positives vs time that was saved because an important design decision was made as a result of the true-positive identification.




% Motivation - justyfing the value of a solution
Get some sources that design principles are important and would cost much less to fix now than later. Also some sources on developer context-change that is beneficial.


before the code is merged into 

can cause important design discussions within the team.
can be used to find where to start reducing technical debt, but is not highly integrated into the development process and asks the questions if the newly developed code is good - while the developer is in the context. The developer can do a consoucious decision to do refactoring before the code is merged in. 

Current tools (linters) have low false-positive rate, but are not able to target important things like the architecture of the application. This tool will be able to target the architecture, but with higher false-positive rate, and through the format of QA hopefully not disturbing the development process too much. 


The motivation is that programming principles are important because they create structure and lay the foundations of building and extending the product.

based on the pre study and own needs i decided to build the tool.

Ok to reference popularity on github/reddit, but can be misvisende and it is important to not take the response there for god fisk.

\subsection{Define objectives of a solution}
\label{objectives-of-solution}

Involves creating a specification of the solution.

General objectives:
\begin{enumerate}
    \item Helps developer and team take important design decisions
    \item Does not create too much noise in the developer workflow
    \item Easy to set up and use
    \item Ok performance
    
\end{enumerate}

Rule specific objectives:


\subsection{Design and development}
Involves the development of the final software artifact and both horizontal and vertical prototypes. Prototypes is used early in the development phases to quickly be able to evaluate the product. Horizontal prototypes should be created to early demonstrate a broad view of the final artifact. Vertical prototypes will be used to elaborate on technical challenges and the workings of specific features. 
 
\subsection{Demonstration}
Gather people for an workshop and presentation of horizontal prototypes. Important to create a structured schema with questions and impressions to get feedback in a structured way that can be used to evaluate the different features.
 
\subsection{Evaluation}

The evaluation is based on the objectives that was defined in section \ref{objectives-of-solution}.

I find that it is super hard to get feedback on something. I think more rules needs to be implemented to be able to get some valueable feedback. Un-structured feedback trough Reddit. Evaluation of github bot as platform for feedback. Evaluation of implemented rules. Evaluate how often the rule gets triggered using a built software system / vs the noise it creates. Evaluate impact on decisions - e.g a commit introduced some inheritance, and later it was found out that inheritance caused trouble. Simulation on other projects to find bugs and false-positives. Used it to further improve the rules and reduce the noise.

Gather a group of Kotlin/Android entusiasts for a workshop where one could order pizza and code using this tool. Focus on feedback. Could for example analyze some code that they know and give some feedback on whether it is useful or not. What would have been useful?

Not that much focus on creating and hitting bullseye with the product, more about the feedback itself and how to respond to it.

Multiple evaluation methods used on different stages of the project: Evaluation running the program on others code, evaluation using a workshop with focus on feedback and usage, evaluation of the initial project using reddit etc.

However, i posted an image of the MVP on Reddit/Kotlin, and it quickly got so many upvotes that it was top this week in under 12 hours. 

\subsection{Communication}


My needs for this solution. Needs a AST to analysis and a framework to help me with this. Need a way of creating a report of the analysis and feed it to something else that can post on github. 


\section{Results}
\subsection{Prototypes}
\subsubsection{Horizontal prototype}
The horizontal prototype was built by creating sample \gls{pr} in a sample repository on Github\cite{sample-repository}, and then commenting on the \gls{pr}'s with the bot user. An example from the prototype is presented in figure \ref{fig:liskov}. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{../demo.png}
    \caption{Prototype of the composition over inheritance / \gls{lsp} rule}
    \label{fig:liskov}
\end{figure}

% What did i find when using this prototype? What changes does the product need, or does it confirm that i am on the right path?

The schema used for evaluation of the prototype, the participants answers and selected images of the prototype can be found in appendix \ref{horizontal-prototype}. The full prototype can be found in the sample repository \cite{sample-repository}. 

\subsubsection{Vertical prototype}
To get structured feedback on the prototype it 
Horizontal prototypes with github PR samples with bot commented. Was easily created by pushing code to repo and logging in as the bot. Should create samples that demonstrates possible false positives as well as true positives. 

\subsection{Workshop}
Schema:
Who is the participants, some background information on them. What did the participants say. What is the takeaway from the workshop? What did i change in the product after having the workshop?

What is the goal, how should i reach the goal of the workshop. Keep the workshop structured.

\subsection{}

\subsection{Short recap of the development process}
Creating a vertical prototype with a simple rule (usecomposition rule) to see if this project it technically possible within the time frame of a masters thesis. 

The schema for the workshop can be found in appendix \ref{workshop-schema}.


\subsection{Detekt-hint specification}
Specification of all the rules.

\subsection{Architecture}
A diagram of how everything interacts with each other.

\subsubsection{Detekt}
Detekt is a static analysis tool for kotlin. Which provides access to a framework for rule creating for analyzing code and reporting warnings.

Detekt gives us access to IntelliJ PSI for analyzing Kotlin code. The PSI is built on top of the \gls{ast} provided by the kotlin compiler, and provides utility methods for modifying and querying of the underlying \gls{ast}.

Type resolution?

\subsubsection{Detekt-hint}

\subsubsection{Danger}

\subsubsection{Danger detekt plugin}

\section{Discussion}
\label{discussion}

\section{Future work}
Implement more rules.
Reducing the amount of false positives.

Providing more context and/or possible solutions in the comments. Images or graphs explaining.
Increasing the performance.
Easing the setup process. Github app? Direct integration with the repository with no setup. A tool like code-climate that does not need any configuration. Plus of tool like this: all setup is in source control. Downside: could be tedious to set up or not all team members want to use it.

\section{Conclusion}
\label{conclusion}

\section{Acknowledgements}
\label{acknowledgements}
Thanks to supervisor, all participants in workshop and prototype sessions.

\printbibliography

\appendix
\label{appendix}
\input{appendix.tex}
\end{document}